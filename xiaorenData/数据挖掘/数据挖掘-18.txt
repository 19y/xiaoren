[{"题干":"Spark DataSet中对两个数据集进行操作的指令不包括","选项F":"","选项E":"","选项D":"distinct","答案":"D","选项C":"intersect","选项B":"union","选项A":"except","类型":"1-单选"},{"题干":"Sark DataSet操作函数中说法错误的是","选项F":"","选项E":"","选项D":"randomSplit对数据集按比例分割","答案":"A","选项C":"orderBy对数据集排序","选项B":"select对数据集选择列","选项A":"sortBy对数据集排序","类型":"1-单选"},{"题干":"模型评估指标中说法错误的是","选项F":"","选项E":"","选项D":"聚类评估指标是离差平方和轮廓系数","答案":"A","选项C":"回归评估指标是均方误差和R平方","选项B":"分类评估指标是准确率和召回率","选项A":"聚类评估指标是均方误差和R平方","类型":"1-单选"},{"题干":"Hadoop环境搭建过程中,需要修改的配置文件主要有哪些","选项F":"","选项E":"","选项D":"spark-env.sh","答案":"D","选项C":"mapred-site.xml","选项B":"hdfs-site.xml","选项A":"core-site.xml","类型":"1-单选"},{"题干":"以下不属于数据预处理过程的是","选项F":"","选项E":"","选项D":"计算召回率","答案":"D","选项C":"归一化","选项B":"删除重复值","选项A":"填补缺失值","类型":"1-单选"},{"题干":"SparkSession在Spark中的作用是","选项F":"","选项E":"","选项D":"可以用来拟合和训练数据的机器学习算法的抽象","答案":"B","选项C":"构建机器学习工作流的容器","选项B":"统一封装了SparkConf、SparkContext、SQLContext，是Spark的唯一入口","选项A":"可以做特征变换和机器学习模型的抽象","类型":"1-单选"},{"题干":"spark机器学习中，构建的工作流用于拟合和训练数据的机器学习算法的抽象是指哪个容器","选项F":"","选项E":"","选项D":"sparkContext","答案":"A","选项C":"Pipeline","选项B":"Transformer","选项A":"Estimators","类型":"1-单选"},{"题干":"Spark RDD中 LabelPoint的说法错误的是","选项F":"","选项E":"","选项D":"通过pyspark.mllib.regression.LabeledPoint实现","答案":"C","选项C":"只能用于聚类问题","选项B":"属性值有标签和特征","选项A":"是一种带有标签的向量","类型":"1-单选"},{"题干":"稠密向量和稀疏向量说法错误的是","选项F":"","选项E":"","选项D":"[1.0,0.0,3.0]是稀疏向量","答案":"D","选项C":"[1.0,0.0,3.0]是稠密向量","选项B":"稀疏向量用SparseVector表示","选项A":"稠密向量用DenseVector表示","类型":"1-单选"},{"题干":"spark中模型评估说法错误的是","选项F":"","选项E":"","选项D":"RegressionMetrics是用于分类评估","答案":"D","选项C":"MulticlassMetrics是用于多分类评估","选项B":"BinaryClassificationMetrics是用于二分类评估","选项A":"RegressionMetrics是用于回归评估","类型":"1-单选"},{"题干":"Spark环境搭建过程中,需要修改的配置文件主要有哪些","选项F":"","选项E":"","选项D":"core-site.xml","答案":"A","选项C":"mapred-site.xml","选项B":"hdfs-site.xml","选项A":"spark-env.sh","类型":"1-单选"},{"题干":"spark mllib中建立决策树分类器的方法类是","选项F":"","选项E":"","选项D":"pyspark.SparkContext","答案":"A","选项C":"pyspark.mllib.evaluation","选项B":"pyspark.mllib.regression","选项A":"pyspark.mllib.tree","类型":"1-单选"},{"题干":"spark ml中建立决策树分类器的方法类是","选项F":"","选项E":"","选项D":"pyspark.sql.functions","答案":"B","选项C":"pyspark.ml.feature","选项B":"pyspark.ml.classification","选项A":"pyspark.ml.tuning","类型":"1-单选"},{"题干":"spark ml中建立交叉验证的方法类是","选项F":"","选项E":"","选项D":"pyspark.sql.functions","答案":"A","选项C":"pyspark.ml.feature","选项B":"pyspark.ml.classification","选项A":"pyspark.ml.tuning","类型":"1-单选"},{"题干":"spark ml中建立网格搜索的方法类是","选项F":"","选项E":"","选项D":"pyspark.ml.tuning","答案":"D","选项C":"pyspark.ml.feature","选项B":"pyspark.ml.classification","选项A":"pyspark.sql.functions","类型":"1-单选"},{"题干":"对Spark DataSet数据集操作的函数说法正确的是","选项F":"","选项E":"","选项D":"以上3条都正确","答案":"ABCD","选项C":"describe()计算数据集中统计信息","选项B":"count()返回数据集中的行数","选项A":"collect()以数组形式返回数据集","类型":"2-多选"},{"题干":"以下属于spark读取文件的指令是","选项F":"","选项E":"","选项D":"spark.read.json","答案":"ABCD","选项C":"spark.read.text","选项B":"spark.read.options","选项A":"spark.read.csv","类型":"2-多选"},{"题干":"以下属于Spark框架内容的是","选项F":"","选项E":"","选项D":"Mahout","答案":"ABC","选项C":"GraphX","选项B":"Streaming","选项A":"SparkSQL","类型":"2-多选"},{"题干":"Spark中数据集发展经历了哪三个过程","选项F":"","选项E":"","选项D":"DataFrame弹性分布式数据集","答案":"ABC","选项C":"Dataset序列化的结构数据","选项B":"DataFrame列结构化的分布式数据集","选项A":"RDD弹性分布式数据集","类型":"2-多选"},{"题干":"Spark中的Pipelines功能主要有哪些","选项F":"","选项E":"","选项D":"统一封装了SparkConf、SparkContext、SQLContext，是Spark的唯一入口","答案":"ABC","选项C":"将多个Transformer和Estimators连接在一起形成一个工作流","选项B":"可以用于各种数据类型转换,构建工作流","选项A":"是spark.ml中用来构建机器学习工作流的容器","类型":"2-多选"},{"题干":"可以用于python连接mysql数据库的模块有","选项F":"","选项E":"","选项D":"pyspark","答案":"ABC","选项C":"sqlalchemy","选项B":"mysqldb","选项A":"pymysql","类型":"2-多选"},{"题干":"以下属于spark ml中的模块，而不属于spark mllib的模块有","选项F":"","选项E":"","选项D":"tuning","答案":"BD","选项C":"evaluation","选项B":"Pipeline","选项A":"regression","类型":"2-多选"},{"题干":"sparkContext中不可以创建RDD的过程","选项F":"","选项E":"","选项D":"","答案":"B","选项C":"","选项B":"","选项A":"","类型":"0-判断"},{"题干":"Spark只需要一次磁盘读写，大部分处理都在内存中进行","选项F":"","选项E":"","选项D":"","答案":"A","选项C":"","选项B":"","选项A":"","类型":"0-判断"},{"题干":"RDD是对DataSet的升级","选项F":"","选项E":"","选项D":"","答案":"B","选项C":"","选项B":"","选项A":"","类型":"0-判断"},{"题干":"spark中toDF操作可以将RDD转化为DataFrame","选项F":"","选项E":"","选项D":"","答案":"A","选项C":"","选项B":"","选项A":"","类型":"0-判断"},{"题干":"输入/opt/spark-1.6.3/bin/pyspark，如果出现spark1.6图标说明pyspark运行正常","选项F":"","选项E":"","选项D":"","答案":"A","选项C":"","选项B":"","选项A":"","类型":"0-判断"}]