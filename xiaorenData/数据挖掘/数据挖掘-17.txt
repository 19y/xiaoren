[{"题干":"sparkContext和sparkSession说法正确的是","选项F":"","选项E":"","选项D":"sparkContext读入的数据是DataFrame数据结构，sparkSession读入的数据是DataFrame数据结构","答案":"A","选项C":"sparkContext读入的数据是DataFrame数据结构，sparkSession读入的数据是RDD数据结构","选项B":"sparkContext读入的数据是RDD数据结构，sparkSession读入的数据是RDD数据结构","选项A":"sparkContext读入的数据是RDD数据结构，sparkSession读入的数据是DataFrame数据结构","类型":"1-单选"},{"题干":"中文文本挖掘主要用的包是","选项F":"","选项E":"","选项D":"scipy","答案":"B","选项C":"sklearn","选项B":"genism","选项A":"seaborn","类型":"1-单选"},{"题干":"英文文本挖掘主要用的包是","选项F":"","选项E":"","选项D":"scipy","答案":"B","选项C":"sklearn","选项B":"nltk","选项A":"seaborn","类型":"1-单选"},{"题干":"RDD.reduceByKey()说法正确的是","选项F":"","选项E":"","选项D":"打印前5行","答案":"B","选项C":"分词","选项B":"按key汇总","选项A":"排序","类型":"1-单选"},{"题干":"RDD.takeOrdered()说法正确的是","选项F":"","选项E":"","选项D":"打印前5行","答案":"B","选项C":"分组统计","选项B":"顺序排列","选项A":"降序排列","类型":"1-单选"},{"题干":"将本地文件传到分布式文件系统中的命令是","选项F":"","选项E":"","选项D":"hdfs dfs -cat","答案":"B","选项C":"hdfs dfs -ls","选项B":"hdfs dfs -put","选项A":"hdfs dfs -get","类型":"1-单选"},{"题干":"初始化分布式文件系统用到的命令是","选项F":"","选项E":"","选项D":"dfs hdfs -format","答案":"B","选项C":"hdfs dfs -format","选项B":"hdfs namenode -format","选项A":"dfs namenode -format","类型":"1-单选"},{"题干":"文本挖掘首先要进行分词处理，英文分词按照空格分割，中文分词使用jieba模块，对于其中的cut方法说法错误的是","选项F":"","选项E":"","选项D":"是否使用HMM模型的参数","答案":"B","选项C":"是否使用全模式的参数","选项B":"词性标注","选项A":"需要分词的字符串","类型":"1-单选"},{"题干":"中文自然语言处理模块是","选项F":"","选项E":"","选项D":"scipy","答案":"B","选项C":"sklearn","选项B":"genism","选项A":"seaborn","类型":"1-单选"},{"题干":"jieba模块中可以用来进行关键词提取的方法类是","选项F":"","选项E":"","选项D":"cut","答案":"C","选项C":"analyse","选项B":"posseg","选项A":"lcut","类型":"1-单选"},{"题干":"hadoop配置文件中，需要设置java路径的文件是","选项F":"","选项E":"","选项D":"slave","答案":"A","选项C":"core-site.xml","选项B":"hdfs-site.xml","选项A":"hadoop-env.sh","类型":"1-单选"},{"题干":"spark是基于内存计算的框架，以下不属于spark组件的是","选项F":"","选项E":"","选项D":"Mahout","答案":"D","选项C":"GraphX","选项B":"Streaming","选项A":"SQL","类型":"1-单选"},{"题干":"启动分布式文件系统的指令是","选项F":"","选项E":"","选项D":"start-dfs.sh","答案":"D","选项C":"start-yarn.sh","选项B":"stop-dfs.sh","选项A":"stop-yarn.sh","类型":"1-单选"},{"题干":"关闭资源调度进程的指令是","选项F":"","选项E":"","选项D":"start-dfs.sh","答案":"A","选项C":"start-yarn.sh","选项B":"stop-dfs.sh","选项A":"stop-yarn.sh","类型":"1-单选"},{"题干":"spark Rdd计算基本统计量用到的方法是","选项F":"","选项E":"","选项D":"join","答案":"B","选项C":"filter","选项B":"stats","选项A":"collect","类型":"1-单选"},{"题干":"jieba模块中可以用来进行词性标注的方法类是","选项F":"","选项E":"","选项D":"cut","答案":"C","选项C":"posseg","选项B":"analyse","选项A":"lcut","类型":"1-单选"},{"题干":"在分布式文件系统中存储数据块的节点是","选项F":"","选项E":"","选项D":"tasktracker","答案":"C","选项C":"Datanode","选项B":"NameNode","选项A":"Jobtracker","类型":"1-单选"},{"题干":"在分布式文件系统中存储元数据或者数据目录的节点是","选项F":"","选项E":"","选项D":"tasktracker","答案":"B","选项C":"Datanode","选项B":"NameNode","选项A":"Jobtracker","类型":"1-单选"},{"题干":"属于spark的进程的是","选项F":"","选项E":"","选项D":"worker","答案":"D","选项C":"nodemanager","选项B":"datanode","选项A":"namenode","类型":"1-单选"},{"题干":"通过哪个接入口可以将数据读为rdd结构","选项F":"","选项E":"","选项D":"sparksession","答案":"A","选项C":"sparkconf","选项B":"sparksql","选项A":"sparkcontext","类型":"1-单选"},{"题干":"spark中用于机器学习的模块是","选项F":"","选项E":"","选项D":"GraphX","答案":"A","选项C":"streaming","选项B":"sql","选项A":"Mllib","类型":"1-单选"},{"题干":"spark中可以建立分类模型的方法类是","选项F":"","选项E":"","选项D":"cluster","答案":"C","选项C":"tree","选项B":"regression","选项A":"evaluation","类型":"1-单选"},{"题干":"spark中计算评估指标的方法类是","选项F":"","选项E":"","选项D":"feature","答案":"A","选项C":"linalg","选项B":"regression","选项A":"evaluation","类型":"1-单选"},{"题干":"以下不属于spark rdd的方法的是","选项F":"","选项E":"","选项D":"head","答案":"D","选项C":"collect","选项B":"count","选项A":"first","类型":"1-单选"},{"题干":"spark rdd进行交集运算的方法是","选项F":"","选项E":"","选项D":"take","答案":"B","选项C":"subtract","选项B":"intersection","选项A":"union","类型":"1-单选"},{"题干":"可以用于文本分类的算法有","选项F":"","选项E":"","选项D":"岭回归","答案":"AB","选项C":"Kmeans","选项B":"决策树","选项A":"朴素贝叶斯","类型":"2-多选"},{"题干":"文本特征提取时，将文本转为词向量的方法有","选项F":"","选项E":"","选项D":"labelenconder","答案":"ABC","选项C":"Word2Vec","选项B":"COUNTVECTORIZER","选项A":"TFIDF","类型":"2-多选"},{"题干":"文本挖掘流程包括","选项F":"","选项E":"","选项D":"建模","答案":"ABCD","选项C":"词向量转换","选项B":"停用词过滤","选项A":"中文分词","类型":"2-多选"},{"题干":"以下方法类中，不属于gensim的方法类是","选项F":"","选项E":"","选项D":"posseg","答案":"CD","选项C":"analyse","选项B":"corpora","选项A":"models","类型":"2-多选"},{"题干":"对于分布式计算框架MapReduce说法不正确的是","选项F":"","选项E":"","选项D":"用户提交的Task会拆分成多个Job任务","答案":"BCD","选项C":"低容错","选项B":"map和reduce同时运行","选项A":"用于大规模数据集的并行运算","类型":"2-多选"},{"题干":"spark词频统计的过程包括以下哪些步骤","选项F":"","选项E":"","选项D":"collect()","答案":"ABCD","选项C":"reduceByKey(lambda x,y:x+y)","选项B":"map(lambda x:(x,1))","选项A":"flatMap(lambda line:line.split())","类型":"2-多选"},{"题干":"对于分布式文件系统说法正确的是","选项F":"","选项E":"","选项D":"NameNode节点只有一个，没有备份","答案":"ABC","选项C":"Block数据块是文件存储的基本单位，默认128MB","选项B":"DataNade是数据存储节点，默认备份三份文件","选项A":"NameNode是Hdfs的元数据节点，负责管理文件目录、文件对应关系","类型":"2-多选"},{"题干":"对于spark框架的说法，正确的是","选项F":"","选项E":"","选项D":"不可以进行机器学习","答案":"ABC","选项C":"方便部署，可以连接各种数据源","选项B":"容易使用，支持多种语言开发","选项A":"运算速度是Hadoop MapReduce的10到100倍","类型":"2-多选"},{"题干":"对文档进行主题建模包括下面哪个步骤","选项F":"","选项E":"","选项D":"analyse.extract_tags方法去除停用词","答案":"AC","选项C":"models.LdaMode方法生成主题模型","选项B":"metrics.precision_score方法计算召回率","选项A":"corpora.Dictionary方法建立词典","类型":"2-多选"},{"题干":"基于统计的分词方法是对上下文中相邻共现的字的组合的频度进行统计，计算它们的互现信息","选项F":"","选项E":"","选项D":"","答案":"A","选项C":"","选项B":"","选项A":"","类型":"0-判断"},{"题干":"spark ml和 spark mlilib区别是操作对象的数据结构不同","选项F":"","选项E":"","选项D":"","答案":"A","选项C":"","选项B":"","选项A":"","类型":"0-判断"},{"题干":"hadoop和spark都是基于内存计算","选项F":"","选项E":"","选项D":"","答案":"B","选项C":"","选项B":"","选项A":"","类型":"0-判断"},{"题干":"sparkContext可以将从外部读入的文件转换为RDD","选项F":"","选项E":"","选项D":"","答案":"A","选项C":"","选项B":"","选项A":"","类型":"0-判断"},{"题干":"sklearn中特征提取用到的方法类是feature_extraction","选项F":"","选项E":"","选项D":"","答案":"A","选项C":"","选项B":"","选项A":"","类型":"0-判断"},{"题干":"MulticlassMetrics是回归模型评估指标","选项F":"","选项E":"","选项D":"","答案":"B","选项C":"","选项B":"","选项A":"","类型":"0-判断"},{"题干":"对rdd数据集进行划分可以使用randomSplit方法","选项F":"","选项E":"","选项D":"","答案":"A","选项C":"","选项B":"","选项A":"","类型":"0-判断"},{"题干":"spark可以直接从hdfs文件系统读取文件","选项F":"","选项E":"","选项D":"","答案":"A","选项C":"","选项B":"","选项A":"","类型":"0-判断"},{"题干":"spark rdd是二维表结构","选项F":"","选项E":"","选项D":"","答案":"B","选项C":"","选项B":"","选项A":"","类型":"0-判断"},{"题干":"Spark SQL是Spark中用于处理结构化数据的模块","选项F":"","选项E":"","选项D":"","答案":"A","选项C":"","选项B":"","选项A":"","类型":"0-判断"},{"题干":"在spark mllib中，建立决策树分类器用到的方法是DecisionTree.trainClassifier","选项F":"","选项E":"","选项D":"","答案":"A","选项C":"","选项B":"","选项A":"","类型":"0-判断"}]