[{"题干":"大数据:决策树中不包含以下哪种结点","选项F":"","选项E":"","选项D":"外部结点","答案":"D","选项C":"叶结点","选项B":"内部结点","选项A":"根结点","类型":"1-单选"},{"题干":"大数据:如果需要训练的特征维度成千上万，在高维情形下出现的数据样本稀疏、距离计算困难。我们通过什么方法可以缓解这个问题","选项F":"","选项E":"","选项D":"降维","答案":"D","选项C":"支持向量机","选项B":"K均值算法","选项A":"其他均不对","类型":"1-单选"},{"题干":"大数据:剪枝处理可以降低什么风险","选项F":"","选项E":"","选项D":"都不对","答案":"B","选项C":"合适拟合","选项B":"过拟合","选项A":"欠拟合","类型":"1-单选"},{"题干":"假设你运作一个公司，并且想开发学习算法来处理两个问题中的一个。\n问题一：数据库中储存了许多客户信息，把他们分成不同的客户群，这样可以根据不同的客户群提供更合适的服务。\n问题二：希望软件检查客户的个人账户，并确定该账户是否被黑客袭击或者是缺乏保护的账户。\n请问这两个问题是分类问题还是聚类问题？","选项F":"","选项E":"","选项D":"都是分类问题","答案":"B","选项C":"问题1是分类问题，问题2是聚类问题","选项B":"问题1是聚类问题，问题2是分类问题","选项A":"都是聚类问题","类型":"1-单选"},{"题干":"大数据:下列方法中，属于特征降维的方法有","选项F":"","选项E":"","选项D":"最小二乘法","答案":"A","选项C":"神经网络","选项B":"梯度下降","选项A":"主成分分析","类型":"1-单选"},{"题干":"大数据:一个SVM存在欠拟合问题，下面怎么的才能提高模型性能","选项F":"","选项E":"","选项D":"以上都不对","答案":"A","选项C":"将参数C的大小调为0","选项B":"减小参数C","选项A":"增大参数C","类型":"1-单选"},{"题干":"以下哪个情况会导致过拟合（高方差）","选项F":"","选项E":"","选项D":"以上都不对","答案":"A","选项C":"C为零的时候","选项B":"C较小（λ较大）的时候","选项A":"C较大（λ较小）的时候","类型":"1-单选"},{"题干":"已知一个数据集，n为特征数，m为训练样本数，如果n较小，而且m大小中等（例如n在1-1000之间，而m在10-10000之间），则一般选择下列哪个核函数的支持向量机","选项F":"","选项E":"","选项D":"多项式核的支持向量机","答案":"C","选项C":"高斯核的支持向量机","选项B":"不带核的支持向量机","选项A":"逻辑回归模型","类型":"1-单选"},{"题干":"大数据:当训练集特征非常多，而实例非常少的时候，可以采用","选项F":"","选项E":"","选项D":"多项式核的支持向量机","答案":"B","选项C":"高斯核的支持向量机","选项B":"不带核的支持向量机","选项A":"sigmoid核的支持向量机","类型":"1-单选"},{"题干":"在机器学习中，决策树算法中不包含以下哪种结点","选项F":"","选项E":"","选项D":"外部结点","答案":"D","选项C":"叶结点","选项B":"内部结点","选项A":"根结点","类型":"1-单选"},{"题干":"在机器学习中，如果需要训练的特征维度成千上万，在高维情形下出现的数据样本稀疏、距离计算困难。我们通过什么方法可以缓解这个问题","选项F":"","选项E":"","选项D":"降维","答案":"D","选项C":"支持向量机","选项B":"K均值算法","选项A":"其他均不对","类型":"1-单选"},{"题干":"在机器学习决策树算法中，剪枝处理可以降低什么风险","选项F":"","选项E":"","选项D":"都不对","答案":"B","选项C":"合适拟合","选项B":"过拟合","选项A":"欠拟合","类型":"1-单选"},{"题干":"假如你运作一个公司，并且你想用学习算法来处理两个问题中的一个。\n\r问题1：数据库中储存了许多客户信息，把他们分成不同的客户群，这样可以根据不同的客户群提供更合适的服务。\n问题2：\r希望软件检查客户的个人账户，并确定该账户是否被黑客袭击或者是缺乏保护的账户。\n请问这两个问题是分类问题还是聚类问题？","选项F":"","选项E":"","选项D":"都是分类问题","答案":"B","选项C":"问题1是分类问题，问题2是聚类问题","选项B":"问题1是聚类问题，问题2是分类问题","选项A":"都是聚类问题","类型":"1-单选"},{"题干":"在机器学习中，下列选项中属于特征降维的方法有","选项F":"","选项E":"","选项D":"最小二乘法","答案":"A","选项C":"神经网络","选项B":"梯度下降","选项A":"主成分分析","类型":"1-单选"},{"题干":"在机器学习中，支持向量机（SVM）存在欠拟合问题，下面怎么的才能提高模型性能","选项F":"","选项E":"","选项D":"以上都不对","答案":"A","选项C":"将参数C的大小调为0","选项B":"减小参数C","选项A":"增大参数C","类型":"1-单选"},{"题干":"在机器学习过程中，什么情况下会导致过拟合（高方差）结果","选项F":"","选项E":"","选项D":"以上都不对","答案":"A","选项C":"C为零的时候","选项B":"C较小（λ较大）的时候","选项A":"C较大（λ较小）的时候","类型":"1-单选"},{"题干":"在机器学习SVM中，已知一个数据集，n为特征数，m为训练样本数，如果n较小，而且m大小中等（例如n在1-1000之间，而m在10-10000之间），则一般选择什么核函数的支持向量机","选项F":"","选项E":"","选项D":"多项式核的支持向量机","答案":"C","选项C":"高斯核的支持向量机","选项B":"不带核的支持向量机","选项A":"逻辑回归模型","类型":"1-单选"},{"题干":"在机器学习中，当训练集特征非常多，而实例非常少的时候，可以采用","选项F":"","选项E":"","选项D":"多项式核的支持向量机","答案":"B","选项C":"高斯核的支持向量机","选项B":"不带核的支持向量机","选项A":"sigmoid核的支持向量机","类型":"1-单选"},{"题干":"大数据:决策树的剪枝分为两种，分别是","选项F":"","选项E":"","选项D":"没有正确答案","答案":"AB","选项C":"插入剪枝","选项B":"后剪枝","选项A":"预剪枝","类型":"2-多选"},{"题干":"大数据:对于决策树的优点描述正确的是","选项F":"","选项E":"","选项D":"是无监督学习","答案":"AB","选项C":"只用于回归问题","选项B":"分类速度快","选项A":"可读性强","类型":"2-多选"},{"题干":"关于k均值算法正确的说法是：","选项F":"","选项E":"","选项D":"K-means在每一次迭代中, 代价函数J(c(1),…,c(m),μ1,…,μk)保持不变或减少，有其它不能增加","答案":"CD","选项C":"一种好的初始化K-means的方法是从训练集中选择K个不同的样本，并将它们设为聚类中心.","选项B":"K-Means无论如何初始化聚类中心，总会得到同样的结果","选项A":"一旦一个样本被分配给一个特定聚类中心，它就不能再分配给另外不同的聚类中心","类型":"2-多选"},{"题干":"大数据:关于主成分分析法PCA以下说法正确的是","选项F":"","选项E":"","选项D":"PCA 只能用于减少1维的数据维数（例如：3维到2维，2维到1维）","答案":"ABC","选项C":"如果输入特征区别很大，在应用PCA之前最好先执行特征缩放","选项B":"PCA不适合进行特征缩放","选项A":"假设输入为多维向量，PCA可以将其压缩为低维向量","类型":"2-多选"},{"题干":"大数据:K均值算法是一个迭代算法，下面哪些步骤是需要反复执行的","选项F":"","选项E":"","选项D":"计算重新生成类的中心；","答案":"CD","选项C":"遍历每一个元素x(i)，计算该元素到各个类中心k的距离，将该元素划分到距其最近的类；","选项B":"初始化，指定k个类的中心位置","选项A":"其余都不对","类型":"2-多选"},{"题干":"机器学习 决策树的剪枝分为两种，分别是","选项F":"","选项E":"","选项D":"没有正确答案","答案":"AB","选项C":"插入剪枝","选项B":"后剪枝","选项A":"预剪枝","类型":"2-多选"},{"题干":"在机器学习中，关于决策树的优点描述正确的是","选项F":"","选项E":"","选项D":"是无监督学习","答案":"AB","选项C":"只用于回归问题","选项B":"分类速度快","选项A":"可读性强","类型":"2-多选"},{"题干":"1534816101772在机器学习\u00A0关于k均值算法正确的说法是：","选项F":"","选项E":"","选项D":"K-means在每一次迭代中,\u00A0代价函数J(c(1),…,c(m),μ1,…,μk)保持不变或减少，有其它不能增加","答案":"CD","选项C":"一种好的初始化K-means的方法是从训练集中选择K个不同的样本，并将它们设为聚类中心.","选项B":"K-Means无论如何初始化聚类中心，总会得到同样的结果","选项A":"一旦一个样本被分配给一个特定聚类中心，它就不能再分配给另外不同的聚类中心","类型":"2-多选"},{"题干":"在机器学习 关于主成分分析法（PCA）以下说法正确的是","选项F":"","选项E":"","选项D":"PCA 只能用于减少1维的数据维数（例如：3维到2维，2维到1维）","答案":"ABC","选项C":"如果输入特征区别很大，在应用PCA之前最好先执行特征缩放","选项B":"PCA不适合进行特征缩放","选项A":"假设输入为多维向量，PCA可以将其压缩为低维向量","类型":"2-多选"},{"题干":"在机器学习中，K均值算法是一个迭代算法，下面哪些步骤是需要反复执行的","选项F":"","选项E":"","选项D":"计算重新生成类的中心；","答案":"CD","选项C":"遍历每一个元素x(i)，计算该元素到各个类中心k的距离，将该元素划分到距其最近的类；","选项B":"初始化，指定k个类的中心位置","选项A":"其余都不对","类型":"2-多选"},{"题干":"大数据:通过降维可以减少冗余信息所造成的误差，提高识别的精度","选项F":"","选项E":"","选项D":"","答案":"A","选项C":"","选项B":"","选项A":"","类型":"0-判断"},{"题干":"大数据:决策树可以用于解决分类问题，也可以用来解决回归问题","选项F":"","选项E":"","选项D":"","答案":"A","选项C":"","选项B":"","选项A":"","类型":"0-判断"},{"题干":"分类间隔的最大化，可以让支持向量机算法具有较好的鲁棒性","选项F":"","选项E":"","选项D":"","答案":"A","选项C":"","选项B":"","选项A":"","类型":"0-判断"},{"题干":"大数据:决策树是有监督的学习算法","选项F":"","选项E":"","选项D":"","答案":"A","选项C":"","选项B":"","选项A":"","类型":"0-判断"},{"题干":"在采用核函数后，svm支持向量机可以用于非线性分类","选项F":"","选项E":"","选项D":"","答案":"A","选项C":"","选项B":"","选项A":"","类型":"0-判断"},{"题干":"大数据:决策树只能用于分类问题，不能用于回归问题","选项F":"","选项E":"","选项D":"","答案":"B","选项C":"","选项B":"","选项A":"","类型":"0-判断"},{"题干":"在机器学习中，通过降维可以减少冗余信息所造成的误差，提高识别的精度","选项F":"","选项E":"","选项D":"","答案":"A","选项C":"","选项B":"","选项A":"","类型":"0-判断"},{"题干":"在机器学习中，决策树可以用于解决分类问题，也可以用来解决回归问题","选项F":"","选项E":"","选项D":"","答案":"A","选项C":"","选项B":"","选项A":"","类型":"0-判断"},{"题干":"机器学习SVM中，分类间隔的最大化，使得支持向量机算法具有较好的鲁棒性","选项F":"","选项E":"","选项D":"","答案":"A","选项C":"","选项B":"","选项A":"","类型":"0-判断"},{"题干":"在机器学习中，决策树是有监督的学习算法","选项F":"","选项E":"","选项D":"","答案":"A","选项C":"","选项B":"","选项A":"","类型":"0-判断"},{"题干":"在机器学习支持向量机算法中，采用核函数后，支持向量机可以用于非线性分类","选项F":"","选项E":"","选项D":"","答案":"A","选项C":"","选项B":"","选项A":"","类型":"0-判断"},{"题干":"在机器学习中，决策树只能用于分类问题，不能用于回归问题","选项F":"","选项E":"","选项D":"","答案":"B","选项C":"","选项B":"","选项A":"","类型":"0-判断"}]