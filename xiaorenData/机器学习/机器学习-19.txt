[{"题干":"在机器学习中，决策树中不包含以下哪种结点","选项F":"","选项E":"","选项D":"外部结点","答案":"D","选项C":"叶结点","选项B":"内部结点","选项A":"根结点","类型":"1-单选"},{"题干":"在机器学习中，剪枝处理可以降低什么风险","选项F":"","选项E":"","选项D":"都不对","答案":"B","选项C":"合适拟合","选项B":"过拟合","选项A":"欠拟合","类型":"1-单选"},{"题干":"在机器学习中，下列方法中，属于特征降维的方法有","选项F":"","选项E":"","选项D":"最小二乘法","答案":"A","选项C":"神经网络","选项B":"梯度下降","选项A":"主成分分析","类型":"1-单选"},{"题干":"关于决策树，以下哪种说法是正确的","选项F":"","选项E":"","选项D":"是无监督学习","答案":"A","选项C":"只用于回归问题","选项B":"只用于分类问题","选项A":"可读性强","类型":"1-单选"},{"题干":"使用ID3算法构建决策树时，树分割的依据是","选项F":"","选项E":"","选项D":"基尼系数","答案":"A","选项C":"信息增益率","选项B":"信息熵","选项A":"信息增益","类型":"1-单选"},{"题干":"决策树解决过拟合问题常用的方法是:","选项F":"","选项E":"","选项D":"都不对","答案":"A","选项C":"减少信息增益","选项B":"增加节点","选项A":"剪枝","类型":"1-单选"},{"题干":"若一个事件发生的概率越高，则其信息熵值","选项F":"","选项E":"","选项D":"都不对","答案":"B","选项C":"不变","选项B":"越小","选项A":"越大","类型":"1-单选"},{"题干":"决策树是建立在已知的历史数据及概率上的，一颗决策树的预测可能会不太准确，提高准确率最好的方法是构建","选项F":"","选项E":"","选项D":"以上都不对","答案":"A","选项C":"后剪枝","选项B":"随机森林","选项A":"预剪枝","类型":"1-单选"},{"题干":"1534815797299有关聚类算法中，k均值算法正确的是：","选项F":"","选项E":"","选项D":"K-means在每一次迭代中,\u00A0代价函数J(c(1),…,c(m),μ1,…,μk)保持不变或增加","答案":"C","选项C":"一种好的初始化K-means的方法是从训练集中选择K个不同的样本，并将它们设为聚类中心.","选项B":"K-Means无论如何初始化聚类中心，总会得到同样的结果","选项A":"一旦一个样本被分配给一个特定聚类中心，它就不能再分配给另外不同的聚类中心","类型":"1-单选"},{"题干":"下面有关主成分分析法PCA说法，不正确的是","选项F":"","选项E":"","选项D":"PCA 只能用于减少1维的数据维数（例如：3维到2维，2维到1维）","答案":"D","选项C":"如果输入特征区别很大，在应用PCA之前最好先执行特征缩放","选项B":"PCA不适合进行特征缩放","选项A":"假设输入为多维向量，PCA可以将其压缩为低维向量","类型":"1-单选"},{"题干":"已知支持向量机的n在1-1000之间，而m在10-10000之间），则通常选择什么核函数的支持向量机","选项F":"","选项E":"","选项D":"多项式核的支持向量机","答案":"C","选项C":"高斯核的支持向量机","选项B":"不带核的支持向量机","选项A":"逻辑回归模型","类型":"1-单选"},{"题干":"支持向量机SVM，若特征数n在1-1000之间，而样本个数m大于50000，则使用支持向量机会非常慢，解决方案是创造、增加更多的特征，然后使用下面哪种支持向量机","选项F":"","选项E":"","选项D":"多项式核的支持向量机","答案":"B","选项C":"高斯核的支持向量机","选项B":"不带核的支持向量机","选项A":"使用sigmoid核函数的支持向量机","类型":"1-单选"},{"题干":"在机器学习中，决策树的剪枝分为两种，分别是","选项F":"","选项E":"","选项D":"没有正确答案","答案":"AB","选项C":"插入剪枝","选项B":"后剪枝","选项A":"预剪枝","类型":"2-多选"},{"题干":"在机器学习中，对于决策树的优点描述正确的是","选项F":"","选项E":"","选项D":"是无监督学习","答案":"AB","选项C":"只用于回归问题","选项B":"分类速度快","选项A":"可读性强","类型":"2-多选"},{"题干":"在机器学习中，关于k均值算法正确的说法是：","选项F":"","选项E":"","选项D":"K-means在每一次迭代中, 代价函数J(c(1),…,c(m),μ1,…,μk)保持不变或减少，有其它不能增加","答案":"CD","选项C":"一种好的初始化K-means的方法是从训练集中选择K个不同的样本，并将它们设为聚类中心.","选项B":"K-Means无论如何初始化聚类中心，总会得到同样的结果","选项A":"一旦一个样本被分配给一个特定聚类中心，它就不能再分配给另外不同的聚类中心","类型":"2-多选"},{"题干":"在机器学习中，关于主成分分析法PCA以下说法正确的是","选项F":"","选项E":"","选项D":"PCA 只能用于减少1维的数据维数（例如：3维到2维，2维到1维）","答案":"ABC","选项C":"如果输入特征区别很大，在应用PCA之前最好先执行特征缩放","选项B":"PCA不适合进行特征缩放","选项A":"假设输入为多维向量，PCA可以将其压缩为低维向量","类型":"2-多选"},{"题干":"在决策树中可以包含哪些节点","选项F":"","选项E":"","选项D":"外部结点","答案":"ABC","选项C":"叶结点","选项B":"内部结点","选项A":"根结点","类型":"2-多选"},{"题干":"决策树为了防止过拟合，可以采用如下哪些方法","选项F":"","选项E":"","选项D":"没有正确答案","答案":"AB","选项C":"插入剪枝","选项B":"后剪枝","选项A":"预剪枝","类型":"2-多选"},{"题干":"若支持向量机存在欠拟合问题，下列哪些方案可以改善","选项F":"","选项E":"","选项D":"减少s","答案":"AD","选项C":"将参数C的大小调为0","选项B":"减小参数C","选项A":"增大参数C","类型":"2-多选"},{"题干":"支持向量机在哪些情况下会导致过拟合（高方差）","选项F":"","选项E":"","选项D":"以上都不对","答案":"AB","选项C":"C为零的时候","选项B":"s较小的时候","选项A":"C较大（λ较小）的时候","类型":"2-多选"},{"题干":"当训练样本m小于特征数n时，即训练集数据量不够支持训练一个复杂的非线性模型时，可采用","选项F":"","选项E":"","选项D":"多项式核的支持向量机","答案":"BA","选项C":"高斯核的支持向量机","选项B":"不带核的支持向量机","选项A":"逻辑回归模型","类型":"2-多选"},{"题干":"聚类问题中的K均值算法是一个迭代算法，其中，哪些部分是需要反复迭代执行的","选项F":"","选项E":"","选项D":"计算重新生成类的中心；","答案":"CD","选项C":"遍历每一个元素x(i)，计算该元素到各个类中心k的距离，将该元素划分到距其最近的类；","选项B":"初始化，指定k个类的中心位置","选项A":"其余都不对","类型":"2-多选"},{"题干":"当遇到过拟合问题时，降维是一个不错的方法","选项F":"","选项E":"","选项D":"","答案":"B","选项C":"","选项B":"","选项A":"","类型":"0-判断"},{"题干":"决策树只能用于解决分类问题","选项F":"","选项E":"","选项D":"","答案":"B","选项C":"","选项B":"","选项A":"","类型":"0-判断"},{"题干":"支持向量机也被认为是最大间隔分类器","选项F":"","选项E":"","选项D":"","答案":"A","选项C":"","选项B":"","选项A":"","类型":"0-判断"},{"题干":"决策树属于无监督的学习算法","选项F":"","选项E":"","选项D":"","答案":"B","选项C":"","选项B":"","选项A":"","类型":"0-判断"},{"题干":"支持向量机通过采用核函数实现非线性分类","选项F":"","选项E":"","选项D":"","答案":"A","选项C":"","选项B":"","选项A":"","类型":"0-判断"},{"题干":"决策树只能用于回归问题","选项F":"","选项E":"","选项D":"","答案":"B","选项C":"","选项B":"","选项A":"","类型":"0-判断"}]