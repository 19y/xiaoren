[{"题干":"关于SecondaryNameNode哪项是正确的？","选项F":"","选项E":"","选项D":"econdaryNameNode应与NameNode部署到一个节点","答案":"C","选项C":"它的目的是帮助NameNode合并编辑日志，减少NameNode启动时间","选项B":"它对内存没有要求","选项A":"它是NameNode的热备","类型":"1-单选"},{"题干":"hadoop1.x中HDFS一个block的默认大小是？","选项F":"","选项E":"","选项D":"128M","答案":"C","选项C":"64MB","选项B":"75MB","选项A":"84MB","类型":"1-单选"},{"题干":"1532501811862HDFS有一个gzip文件大小75MB，客户端设置Block大小为64MB。当运行mapreduce任务读取该文件时input\u00A0split大小为？","选项F":"","选项E":"","选项D":"128M","答案":"B","选项C":"一个map读取64MB，另外一个map读取11MB","选项B":"75MB","选项A":"64MB","类型":"1-单选"},{"题干":"下列关于MapReduce说法不正确的是","选项F":"","选项E":"","选项D":"MapReduce隐藏了并行计算的细节，方便使用","答案":"C","选项C":"MapReduce程序只能用java语言编写","选项B":"MapReduce来源于google的学术论文","选项A":"MapReduce是一种计算框架","类型":"1-单选"},{"题干":"下列关于Hadoop\u00A0API的说法错误的是","选项F":"","选项E":"","选项D":"FSDataInputStream是java.io.DataInputStream的子类","答案":"A","选项C":"FileStatus对象存储文件和目录的元数据","选项B":"Configuration类的默认实例化方法是以HDFS系统的资源配置为基础的","选项A":"Hadoop的文件API不是通用的，只用于HDFS文件系统","类型":"1-单选"},{"题干":"Hadoop\u00A0fs中的-put和-get命令操作对象是","选项F":"","选项E":"","选项D":"以上都不对","答案":"C","选项C":"以上两者都是","选项B":"目录","选项A":"文件","类型":"1-单选"},{"题干":"关于HDFS的文件写入，正确的是","选项F":"","选项E":"","选项D":"复制的文件块默认都存在同一机架上","答案":"C","选项C":"默认将文件块复制成三份存放","选项B":"用户可以在文件任意位置进行修改","选项A":"支持多用户对同一文件的写操作","类型":"1-单选"},{"题干":"Hadoop fs中的-get和-put命令操作对象是","选项F":"","选项E":"","选项D":"以上都不对","答案":"C","选项C":"以上两者都是","选项B":"目录","选项A":"文件","类型":"1-单选"},{"题干":"下列哪个属性是hdfs-site.xml中的配置？","选项F":"","选项E":"","选项D":"yarn.resourcemanager.address","答案":"A","选项C":"mapreduce.framework.name","选项B":"fs.defaultFS","选项A":"dfs.replication","类型":"1-单选"},{"题干":"如果我们现有一个安装2.6.5版本的hadoop集群，在不修改默认配置的情况下存储200个每个200M的文本文件，请问最终会在集群中产生多少个数据块（包括副本）？","选项F":"","选项E":"","选项D":"1200","答案":"D","选项C":"400","选项B":"40000","选项A":"200","类型":"1-单选"},{"题干":"hdfs以什么为单位存放数据","选项F":"","选项E":"","选项D":"个数","答案":"C","选项C":"块","选项B":"批","选项A":"文件","类型":"1-单选"},{"题干":"以下哪个命令是启动yarn","选项F":"","选项E":"","选项D":"start-dfs.sh","答案":"A","选项C":"start-all.sh","选项B":"start.sh","选项A":"start-yarn.sh","类型":"1-单选"},{"题干":"hdfs查看文件目录结构命令是","选项F":"","选项E":"","选项D":"hadoop�fs�-l","答案":"A","选项C":"hadoop�fs�-list","选项B":"hadoop�fs�-show","选项A":"hadoop�fs�-ls","类型":"1-单选"},{"题干":"关于yarn的说法，其中正确的是哪个？","选项F":"","选项E":"","选项D":"其他都是","答案":"D","选项C":"它的引入为集群在利用率、资源统一管理和数据共享等方面带来了巨大好处","选项B":"它是一个通用资源管理系统，可为上层应用提供统一的资源管理和调度","选项A":"是一种新的\u00A0Hadoop\u00A0资源管理器","类型":"1-单选"},{"题干":"NameNode和DataNode之间的通讯机制是什么","选项F":"","选项E":"","选项D":"ajax","答案":"A","选项C":"http请求","选项B":"webservice","选项A":"心跳机制","类型":"1-单选"},{"题干":"可以在web中通过哪个端口访问NameNode？","选项F":"","选项E":"","选项D":"50000","答案":"A","选项C":"80","选项B":"8080","选项A":"50070","类型":"1-单选"},{"题干":"假设block的大小为128M,如果有两个文件的大小分别为129M和1K，请问在hdfs上需要被切分成几块？","选项F":"","选项E":"","选项D":"4","答案":"C","选项C":"3","选项B":"2","选项A":"1","类型":"1-单选"},{"题干":"hdfs元数据是放在什么地方？","选项F":"","选项E":"","选项D":"主板","答案":"A","选项C":"CPU","选项B":"磁盘","选项A":"内存","类型":"1-单选"},{"题干":"配置Hadoop时，JAVA_HOME的配置在哪一个配置文件中","选项F":"","选项E":"","选项D":"configuration.xsl","答案":"B","选项C":"hadoop-site.xml","选项B":"hadoop-env.sh","选项A":"hadoop-default.xml","类型":"1-单选"},{"题干":"关于Hadoop单机运行模式和伪分布式运行模式的说法，正确的是","选项F":"","选项E":"","选项D":"后者比前者增加了HDFS输入输出以及可检查内存使用情况","答案":"D","选项C":"两者都不与守护进程交互，避免复杂性","选项B":"单机模式不使用HDFS，但加载守护进程","选项A":"两者都起守护进程，且守护进程运行在一台机器上","类型":"1-单选"},{"题干":"HDFS有一个普通本文件大小75MB，设客户端设置Block大小为64MB。当运行mapreduce任务读取该文件时input split大小为？","选项F":"","选项E":"","选项D":"128M","答案":"C","选项C":"一个map读取64MB，另外一个map读取11MB","选项B":"75MB","选项A":"64MB","类型":"1-单选"},{"题干":"配置机架感知的下面哪项正确","选项F":"","选项E":"","选项D":"以上都不对","答案":"ABC","选项C":"MapReduce会根据机架获取离自己比较近的网络数据","选项B":"写入数据的时候会写到不同机架的DataNode中","选项A":"如果一个机架出问题，不会影响数据读写","类型":"2-多选"},{"题干":"Client端上传文件的时候下列哪项正确","选项F":"","选项E":"","选项D":"当某个DataNode失败，客户端会继续传给其它DataNode","答案":"BD","选项C":"Client只上传数据到一台DataNode，然后由NameNode负责Block复制工作","选项B":"Client端将文件以Block为单位，管道方式依次传到DataNode","选项A":"数据经过NameNode传递给DataNode","类型":"2-多选"},{"题干":"MySql中对于删除操作以下说法正确的是（）","选项F":"","选项E":"","选项D":"drop table 表名：删除表","答案":"ABCD","选项C":"delete from 表名 where 字段名=值：删除符合条件的记录条","选项B":"delete from 表名：删除表中所有记录条","选项A":"drop database 数据库名：删除数据库","类型":"2-多选"},{"题干":"类B是一个抽象类，类C是类B的非抽象子类，下列创建对象x1的语句中正确的是","选项F":"","选项E":"","选项D":"C x1= new B( );","答案":"BC","选项C":"C x1=new C( );","选项B":"B x1= new C( );","选项A":"B x1= new B( );","类型":"2-多选"},{"题干":"以下属于面向对象的基本特征的是（  ）。","选项F":"","选项E":"","选项D":"可移植","答案":"ABC","选项C":"多态","选项B":"继承","选项A":"封装","类型":"2-多选"},{"题干":"SecondaryNameNode在哪些情况下开始合并元数据文件","选项F":"","选项E":"","选项D":"内存满了之后","答案":"AB","选项C":"随时合并","选项B":"操作日志文件超过了一定的大小","选项A":"达到了一定的时间间隔","类型":"2-多选"},{"题干":"NameNode中的数据包括以下哪些内容？","选项F":"","选项E":"","选项D":"最后一次合并镜像文件时间fstime","答案":"ACD","选项C":"操作日志文件edits.log","选项B":"secondarynamenode","选项A":"镜像文件fsimage","类型":"2-多选"},{"题干":"下面哪些命令可以将文件从Linux上传到hdfs上","选项F":"","选项E":"","选项D":"copyToLocal","答案":"AB","选项C":"upload","选项B":"put","选项A":"copyFromLocal","类型":"2-多选"},{"题干":"下面哪些命令可以将文件从hdfs下载文件到Linux上","选项F":"","选项E":"","选项D":"download","答案":"ABC","选项C":"getmerge","选项B":"copyToLocal","选项A":"get","类型":"2-多选"},{"题干":"以下哪些是secondarynamenode在合并fsimage期间做的事情？","选项F":"","选项E":"","选项D":"将新的fsimage发回给namenode","答案":"ABCD","选项C":"将fsimage载入内存，然后开始合并edits","选项B":"从namenode获得fsimage和edits","选项A":"通知namenode切换edits文件","类型":"2-多选"},{"题干":"Java中import语句通常出现在package语句之前","选项F":"","选项E":"","选项D":"","答案":"B","选项C":"","选项B":"","选项A":"","类型":"0-判断"},{"题干":"Java语言，当方法中的返回值类型是void时，可以不写return语句","选项F":"","选项E":"","选项D":"","答案":"A","选项C":"","选项B":"","选项A":"","类型":"0-判断"},{"题干":"程序调用自身的编程技巧称为递归","选项F":"","选项E":"","选项D":"","答案":"A","选项C":"","选项B":"","选项A":"","类型":"0-判断"},{"题干":"数组获取长度使用length（）方法","选项F":"","选项E":"","选项D":"","答案":"B","选项C":"","选项B":"","选项A":"","类型":"0-判断"},{"题干":"javac命令可以运行Demo.class文件","选项F":"","选项E":"","选项D":"","答案":"B","选项C":"","选项B":"","选项A":"","类型":"0-判断"},{"题干":"HDFS不能临时再添加DataNode","选项F":"","选项E":"","选项D":"","答案":"B","选项C":"","选项B":"","选项A":"","类型":"0-判断"},{"题干":"secondarynamenode应该和NameNode配置在同一个节点上启动","选项F":"","选项E":"","选项D":"","答案":"B","选项C":"","选项B":"","选项A":"","类型":"0-判断"},{"题干":"如果\u00A0NameNode\u00A0意外终止，SecondaryNameNode\u00A0会转化为NameNode","选项F":"","选项E":"","选项D":"","答案":"B","选项C":"","选项B":"","选项A":"","类型":"0-判断"},{"题干":"HDFS的namenode保存了一个文件包括哪些数据块，分布在哪些数据节点上等信息","选项F":"","选项E":"","选项D":"","答案":"B","选项C":"","选项B":"","选项A":"","类型":"0-判断"},{"题干":"因为HDFS有多个副本，所以NameNode不存在单点问题的。","选项F":"","选项E":"","选项D":"","答案":"B","选项C":"","选项B":"","选项A":"","类型":"0-判断"}]