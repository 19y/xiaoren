[{"题干":"1534480509如果自己编写一个类来作为key在Map和Reduce之间传递数据，那么这个类需要实现哪个接口","选项F":"","选项E":"","选项D":"IntWritable","答案":"B","选项C":"LongWritable","选项B":"WritableComparable","选项A":"Serializble","类型":"1-单选"},{"题干":"1534480509Spring框架的配置文件默认的是","选项F":"","选项E":"","选项D":"applicationContext.xml","答案":"D","选项C":"hibernate.cfg.xml","选项B":"struts.xml","选项A":"spring.xml","类型":"1-单选"},{"题干":"java实现序列化的接口是","选项F":"","选项E":"","选项D":"IntWritable","答案":"A","选项C":"LongWritable","选项B":"WritableComparable","选项A":"Serializable","类型":"1-单选"},{"题干":"1534480509用命令ls -al显示出文件ff的描述为 drwxr-xr-- 1 root root 599 Cec 10 17:12 ff ，由此可知文件ff的类型为","选项F":"","选项E":"","选项D":"文件夹","答案":"D","选项C":"符号链接","选项B":"硬链接","选项A":"普通文件","类型":"1-单选"},{"题干":"1534480509HDfS 中的 block 默认保存几份？","选项F":"","选项E":"","选项D":"不确定","答案":"A","选项C":"1","选项B":"2","选项A":"3","类型":"1-单选"},{"题干":"1534480509SecondaryNameNode是什么？","选项F":"","选项E":"","选项D":"SecondaryNameNode 应与 NameNode 部署到一个节点","答案":"C","选项C":"它的目的是帮助 NameNode 合并编辑日志，减少 NameNode 启动时间","选项B":"它对内存没有要求","选项A":"它是 NameNode 的热备","类型":"1-单选"},{"题干":"1534480509下面哪个方法可以帮我们生成40到100之间的随机数num？","选项F":"","选项E":"","选项D":"Random r = new Random();\nint num = r.nextInt(100)+40;","答案":"C","选项C":"Random r = new Random();\nint num = r.nextInt(60)+40;","选项B":"Random r = new Random();\nint num = r.nextInt(40);","选项A":"Random r = new Random();\nint num = r.nextInt(100);","类型":"1-单选"},{"题干":"1534480509以下关于MapReduce说法错误的是（）","选项F":"","选项E":"","选项D":"Mapper切分任务的时候，可以随意切分","答案":"D","选项C":"Mapper切分出的各个小任务相对于以前的大任务应该大大缩减计算量","选项B":"Mapper分成的各个小任务应该可以并行计算，彼此之间没有依赖关系","选项A":"Mapper阶段的作用是把复杂的任务拆分成若干个小任务","类型":"1-单选"},{"题干":"1534480509下列哪种业务场景中，不能直接使用Reducer充当Combiner使用？","选项F":"","选项E":"","选项D":"avg求平均","答案":"D","选项C":"count求计数","选项B":"max求最大值","选项A":"sum求和","类型":"1-单选"},{"题干":"1534480509MapReduce框架提供了一种序列化键/值对的方法，支持这种序列化的类能够在Map和Reduce过程中充当键或值，以下说法错误的是","选项F":"","选项E":"","选项D":"键和值的数据类型可以超出Hadoop自身支持的基本类型","答案":"C","选项C":"Hadoop的基本类型Text并不实现WritableComparable<T>接口","选项B":"实现WritableComparable<T>接口的类可以是值或键","选项A":"实现Writable接口的类是值","类型":"1-单选"},{"题干":"HDFS的进程不包括以下","选项F":"","选项E":"","选项D":"namenode","答案":"C","选项C":"yarnchild","选项B":"datanode","选项A":"secondarynamenode","类型":"1-单选"},{"题干":"HDFS集群中的namenode职责不包括以下哪个？","选项F":"","选项E":"","选项D":"响应客户端的所有读写数据请求","答案":"C","选项C":"负责保存客户端上传的数据","选项B":"维护HDFS集群的所有数据块的分布、副本数和负载均衡","选项A":"维护HDFS集群的目录树结构","类型":"1-单选"},{"题干":"关于HDFS集群中的datanode的以下描述中不正确的是","选项F":"","选项E":"","选项D":"响应客户端的所有读写数据请求，为客户端的存储和读取数据提供支撑","答案":"C","选项C":"一个datanode上存储的所有数据块可以有相同的","选项B":"存储客户端上传的数据的数据块","选项A":"datanode上的数据是以快为单位存储","类型":"1-单选"},{"题干":"HDFS的datenode的主要职责是","选项F":"","选项E":"","选项D":"响应客户端的所有读写数据请求","答案":"C","选项C":"负责保存客户端上传的数据","选项B":"维护HDFS集群的所有数据块的分布、副本数和负载均衡","选项A":"维护HDFS集群的目录树结构","类型":"1-单选"},{"题干":"MapReduce的Shuffle中哪个操作是最后做的？","选项F":"","选项E":"","选项D":"合并","答案":"D","选项C":"排序","选项B":"分区","选项A":"溢写","类型":"1-单选"},{"题干":"Java判断一个字符串是否以某个字符开头的方法是","选项F":"","选项E":"","选项D":"length()","答案":"A","选项C":"substring()","选项B":"endWith()","选项A":"startWith()","类型":"1-单选"},{"题干":"Java判断一个字符串是否以某个字符结尾的方法是","选项F":"","选项E":"","选项D":"length()","答案":"B","选项C":"substring()","选项B":"endWith()","选项A":"startWith()","类型":"1-单选"},{"题干":"以下哪个命令专门用于列出Java相关进程？","选项F":"","选项E":"","选项D":"p","答案":"B","选项C":"jsp","选项B":"jps","选项A":"ps","类型":"1-单选"},{"题干":"hdfs命令中查看文件目录结构的命令为","选项F":"","选项E":"","选项D":"hadoop�fs�-l","答案":"A","选项C":"hadoop�fs�-list","选项B":"hadoop�fs�-show","选项A":"hadoop�fs�-ls","类型":"1-单选"},{"题干":"hdfs中NameNode和DataNode之间的通讯机制是","选项F":"","选项E":"","选项D":"ajax","答案":"A","选项C":"http请求","选项B":"webservice","选项A":"心跳机制","类型":"1-单选"},{"题干":"如果自己编写一个类来作为key在Map和Reduce之间传递数据，那么这个类需要实现以下哪个接口","选项F":"","选项E":"","选项D":"IntWritable","答案":"B","选项C":"LongWritable","选项B":"WritableComparable","选项A":"Serializble","类型":"1-单选"},{"题干":"Spring框架的配置文件默认的名称是","选项F":"","选项E":"","选项D":"applicationContext.xml","答案":"D","选项C":"hibernate.cfg.xml","选项B":"struts.xml","选项A":"spring.xml","类型":"1-单选"},{"题干":"下列哪种类型的文件不是HDFS的元数据存储格式？","选项F":"","选项E":"","选项D":"blk_000003425","答案":"D","选项C":"edits_inprogress","选项B":"edits","选项A":"fsimage","类型":"1-单选"},{"题干":"用命令ls -al显示出文件ff的描述为 drwxr-xr-- 1 root root 599 Cec 10 17:12 dd ，由此可知文件dd的类型为","选项F":"","选项E":"","选项D":"文件夹","答案":"D","选项C":"符号链接","选项B":"硬链接","选项A":"普通文件","类型":"1-单选"},{"题干":"HDfS 中的 block 默认保存多少份？","选项F":"","选项E":"","选项D":"不确定","答案":"A","选项C":"1","选项B":"2","选项A":"3","类型":"1-单选"},{"题干":"SecondaryNameNode指的是什么？","选项F":"","选项E":"","选项D":"SecondaryNameNode 应与 NameNode 部署到一个节点","答案":"C","选项C":"它的目的是帮助 NameNode 合并编辑日志，减少 NameNode 启动时间","选项B":"它对内存没有要求","选项A":"它是 NameNode 的热备","类型":"1-单选"},{"题干":"下列选项中哪个方法可以帮我们生成40到100之间的随机数num？","选项F":"","选项E":"","选项D":"Random r = new Random();\nint num = r.nextInt(100)+40;","答案":"C","选项C":"Random r = new Random();\nint num = r.nextInt(60)+40;","选项B":"Random r = new Random();\nint num = r.nextInt(40);","选项A":"Random r = new Random();\nint num = r.nextInt(100);","类型":"1-单选"},{"题干":"以下关于MapReduce的描述错误的是（）","选项F":"","选项E":"","选项D":"Mapper切分任务的时候，可以随意切分","答案":"D","选项C":"Mapper切分出的各个小任务相对于以前的大任务应该大大缩减计算量","选项B":"Mapper分成的各个小任务应该可以并行计算，彼此之间没有依赖关系","选项A":"Mapper阶段的作用是把复杂的任务拆分成若干个小任务","类型":"1-单选"},{"题干":"下列哪种业务需求中，不能直接使用Reducer充当Combiner使用？","选项F":"","选项E":"","选项D":"avg求平均","答案":"D","选项C":"count求计数","选项B":"max求最大值","选项A":"sum求和","类型":"1-单选"},{"题干":"以下哪些类型能用作Mapper的key。( )","选项F":"","选项E":"","选项D":"NullWritable","答案":"BD","选项C":"Null","选项B":"Text","选项A":"String","类型":"2-多选"},{"题干":"以下哪个语句执行结果返回true;","选项F":"","选项E":"","选项D":"false?true:false","答案":"BC","选项C":"false?false:true","选项B":"true?true:false","选项A":"true?false:true","类型":"2-多选"},{"题干":"Combiner有什么作用","选项F":"","选项E":"","选项D":"所有的MapReduce中都可以使用","答案":"AB","选项C":"可以替代Reduce","选项B":"可以提高MapReduce运行效率","选项A":"可以节省网络资源","类型":"2-多选"},{"题干":"关于NodeManager, 描述正确的有","选项F":"","选项E":"","选项D":"单个节点上资源管理和任务管理","答案":"ABCD","选项C":"处理来至\u00A0ApplicationMaster\u00A0的命令","选项B":"处理来至\u00A0ResourceManager\u00A0的命令","选项A":"集群中可以有多个","类型":"2-多选"},{"题干":"关于ApplicationMaster，描述正确的有","选项F":"","选项E":"","选项D":"容错处理","答案":"ABCD","选项C":"为应用向\u00A0ResourceManager\u00A0申请计算资源","选项B":"分布式计算数据的切片","选项A":"每个应用有一个，\u00A0负责应用程序整个生命周期的管理","类型":"2-多选"},{"题干":"以下哪些是MapReduce的优点","选项F":"","选项E":"","选项D":"编程容易","答案":"ABCD","选项C":"高容错性","选项B":"适合PB级别以上的海量数据的离线处理","选项A":"扩展性良好","类型":"2-多选"},{"题干":"以下哪些是MapReduce计算框架不能实现的","选项F":"","选项E":"","选项D":"处理变化的数据","答案":"AD","选项C":"扩展性","选项B":"高容错","选项A":"实时计算","类型":"2-多选"},{"题干":"以下关于\u00A0NodeManager\u00A0的说法中正确的有","选项F":"","选项E":"","选项D":"处理来至\u00A0ResourceManager\u00A0的命令","答案":"ABCD","选项C":"处理来至\u00A0ApplicationMaster\u00A0的命令","选项B":"单个节点上资源管理和任务管理","选项A":"集群中可以有多个","类型":"2-多选"},{"题干":"以下关于\u00A0ApplicationMaster\u00A0的说法中正确的有","选项F":"","选项E":"","选项D":"分布式计算数据的切片","答案":"ABCD","选项C":"为应用向\u00A0ResourceManager\u00A0申请计算资源","选项B":"容错处理","选项A":"每个应用有一个，\u00A0负责应用程序整个生命周期的管理","类型":"2-多选"},{"题干":"以下属于是Java基本类型中浮点类型的是（\u00A0\u00A0）","选项F":"","选项E":"","选项D":"long","答案":"AB","选项C":"int","选项B":"double","选项A":"float","类型":"2-多选"},{"题干":"MapReduce运算的特点是移动计算而不是移动数据","选项F":"","选项E":"","选项D":"","答案":"A","选项C":"","选项B":"","选项A":"","类型":"0-判断"},{"题干":"MapReduce计算的时候，shuffle阶段是最重要的阶段，被称为mapreduce的心脏","选项F":"","选项E":"","选项D":"","答案":"A","选项C":"","选项B":"","选项A":"","类型":"0-判断"},{"题干":"Hadoop 支持数据的随机读写","选项F":"","选项E":"","选项D":"","答案":"B","选项C":"","选项B":"","选项A":"","类型":"0-判断"},{"题干":"NameNode负责管理metadata，client端每次读写请求，它都会从磁盘中读取或则会写入metadata信息并反馈client端。","选项F":"","选项E":"","选项D":"","答案":"B","选项C":"","选项B":"","选项A":"","类型":"0-判断"},{"题干":"Hadoop1.0和2.0都具备完善的HDFS HA策略。","选项F":"","选项E":"","选项D":"","答案":"B","选项C":"","选项B":"","选项A":"","类型":"0-判断"},{"题干":"MapReduce运算的思想是移动计算而非移动数据","选项F":"","选项E":"","选项D":"","答案":"A","选项C":"","选项B":"","选项A":"","类型":"0-判断"},{"题干":"MapReduce中，shuffle阶段是最重要的阶段，是mapreduce的心脏","选项F":"","选项E":"","选项D":"","答案":"A","选项C":"","选项B":"","选项A":"","类型":"0-判断"},{"题干":"shuffle会按照key进行合并和排序","选项F":"","选项E":"","选项D":"","答案":"A","选项C":"","选项B":"","选项A":"","类型":"0-判断"},{"题干":"编写MapReduce的启动程序的时候，设置Mapper类的方法是job.setMapperClass()","选项F":"","选项E":"","选项D":"","答案":"A","选项C":"","选项B":"","选项A":"","类型":"0-判断"},{"题干":"System.out.println(3\u00A0/\u00A02);的运行结果是1.5。","选项F":"","选项E":"","选项D":"","答案":"B","选项C":"","选项B":"","选项A":"","类型":"0-判断"}]