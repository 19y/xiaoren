[{"题干":"给定神经网络，AW = Y，其中A是训练集合，Y是标签集合，总体损失函数E一般表示为是：","选项F":"","选项E":"","选项D":"（AX-Y）","答案":"A","选项C":"Y对X的偏导数","选项B":"（Y-AX）","选项A":"0.5乘（Y-AX）的范数平方","类型":"1-单选"},{"题干":"复合函数h(f(g(x)))对x的导数是：","选项F":"","选项E":"","选项D":"h对g的导数","答案":"A","选项C":"h对f的导数","选项B":"h对x的导数","选项A":"（h对f的导数）乘（f对g的导数）乘（g对x的导数）","类型":"1-单选"},{"题干":"y=sigmoid（x）函数对x的导数可以写成","选项F":"","选项E":"","选项D":"y（1-y）","答案":"D","选项C":"1-exp（-x）","选项B":"exp（-x）","选项A":"y（1+y）","类型":"1-单选"},{"题干":"全连接神经网络，如果输入层为32X4矩阵，那么与它相连的第一级参数矩阵最有可能为：","选项F":"","选项E":"","选项D":"任意尺寸矩阵","答案":"A","选项C":"32X32矩阵","选项B":"32X4矩阵","选项A":"4X5矩阵","类型":"1-单选"},{"题干":"tf.nn.conv2d(a, b, c, d )，其中池化操作是","选项F":"","选项E":"","选项D":"d","答案":"D","选项C":"c","选项B":"b","选项A":"a","类型":"1-单选"},{"题干":"tf.nn.conv2d(batch,  in_height, in_width, in_channels)，其中batch是","选项F":"","选项E":"","选项D":"通道数","答案":"B","选项C":"步长","选项B":"图像数","选项A":"卷积核","类型":"1-单选"},{"题干":"1532923634是否听明白此知识点：13.1将流程设计转换成tensorflow脚本","选项F":"","选项E":"","选项D":"","答案":"A","选项C":"","选项B":"否","选项A":"是","类型":"1-单选"},{"题干":"1532923634是否听明白此知识点：\t13.1.2如何用tensorflow表达任意流程","选项F":"","选项E":"","选项D":"","答案":"A","选项C":"","选项B":"否","选项A":"是","类型":"1-单选"},{"题干":"1532923634是否听明白此知识点：13.2tensorflow做几个具体流程","选项F":"","选项E":"","选项D":"","答案":"A","选项C":"","选项B":"否","选项A":"是","类型":"1-单选"},{"题干":"1532923634是否听明白此知识点：13.3tensorflow实现BP网络（对照Python的相同实现）","选项F":"","选项E":"","选项D":"","答案":"A","选项C":"","选项B":"否","选项A":"是","类型":"1-单选"},{"题干":"1532923634是否听明白此知识点：13.4如何协调Python的tensorflow语言分工","选项F":"","选项E":"","选项D":"","答案":"A","选项C":"","选项B":"否","选项A":"是","类型":"1-单选"},{"题干":"对于神经网络，AW = Y，其中A是训练集合，Y是标签集合，总体损失函数E一般表示为是：","选项F":"","选项E":"","选项D":"（AX-Y）","答案":"A","选项C":"Y对X的偏导数","选项B":"（Y-AX）","选项A":"0.5乘（Y-AX）的范数平方","类型":"1-单选"},{"题干":"对于复合函数h(f(g(x)))，对x的导数是：","选项F":"","选项E":"","选项D":"h对g的导数","答案":"A","选项C":"h对f的导数","选项B":"h对x的导数","选项A":"（h对f的导数）乘（f对g的导数）乘（g对x的导数）","类型":"1-单选"},{"题干":"对y=sigmoid（x）函数对x的导数可以写成","选项F":"","选项E":"","选项D":"y（1-y）","答案":"D","选项C":"1-exp（-x）","选项B":"exp（-x）","选项A":"y（1+y）","类型":"1-单选"},{"题干":"在全连接神经网络，如果输入层为32X4矩阵，那么与它相连的第一级参数矩阵最有可能为：","选项F":"","选项E":"","选项D":"任意尺寸矩阵","答案":"A","选项C":"32X32矩阵","选项B":"32X4矩阵","选项A":"4X5矩阵","类型":"1-单选"},{"题干":"在tf.nn.conv2d(a, b, c, d )，其中填充操作是","选项F":"","选项E":"","选项D":"d","答案":"D","选项C":"c","选项B":"b","选项A":"a","类型":"1-单选"},{"题干":"在一个32X32大小的图像，通过步长为2，不考虑填充，尺寸为2X2的池化运算后，尺寸变为","选项F":"","选项E":"","选项D":"16X16","答案":"D","选项C":"28X28","选项B":"2X2","选项A":"14X14","类型":"1-单选"},{"题干":"在一个32X32大小的图像，通过步长为1，不考虑填充，大小为5X5的卷积核卷积后，结果尺寸成为","选项F":"","选项E":"","选项D":"32X32","答案":"A","选项C":"31X31","选项B":"14X14","选项A":"28X28","类型":"1-单选"},{"题干":"在tf.nn.conv2d(【batch,  in_height, in_width, in_channels】，W，S，P)，其中batch是","选项F":"","选项E":"","选项D":"通道数","答案":"B","选项C":"步长","选项B":"图像数","选项A":"卷积核","类型":"1-单选"},{"题干":"定义卷积核W_conv1 = weight_variable([5, 5, 5, 32])后","选项F":"","选项E":"","选项D":"有32个卷积核","答案":"ABCD","选项C":"输出通道32","选项B":"输入通道5","选项A":"尺寸5X5","类型":"2-多选"},{"题干":"关于sigmoid函数，它的性质有：","选项F":"","选项E":"","选项D":"将正权值映射到负数","答案":"ABC","选项C":"将负的权值映射到正值","选项B":"能解决非线性分类问题","选项A":"将输出数据压缩到【0，1】集合范围","类型":"2-多选"},{"题干":"关于深度神经网络的构成，将卷积层放在前面，将全连接层放在后面，它们的作用是","选项F":"","选项E":"","选项D":"全连接层只能有一层","答案":"ABC","选项C":"激活函数relu可以用到卷积层","选项B":"pooling的下采样能够降低overfitting","选项A":"用卷积层提取特征","类型":"2-多选"},{"题干":"在tensorflow中，x = tf.cast(u,tf.float32)的意义，说法正确的是","选项F":"","选项E":"","选项D":"实现类型转化的功能","答案":"BD","选项C":"将u内的数据进行洗牌处理","选项B":"将u内数据转换成float32","选项A":"将随机数赋值给u","类型":"2-多选"},{"题干":"w_data = np.mat([[1.0, 3.0]]).T生成的张量维度是","选项F":"","选项E":"","选项D":"是向量【1，3】的转置","答案":"ACD","选项C":"是矩阵【【1】，【3】】","选项B":"是向量，值为【1，3】","选项A":"维度是【2，1】的张量","类型":"2-多选"},{"题干":"以下哪条tf语句能够描述损失函数","选项F":"","选项E":"","选项D":"loss = tf.reduce_mean(tf.subtract(y，y_data))","答案":"AB","选项C":"loss = tf.reduce_mean(tf.add(y，y_data))","选项B":"loss = tf.reduce_sum(tf.square(y - y_data))","选项A":"loss = tf.reduce_mean(tf.square(y - y_data))","类型":"2-多选"},{"题干":"在定义卷积核W_conv1 = weight_variable([5, 5, 5, 32])后","选项F":"","选项E":"","选项D":"有32个卷积核","答案":"ABCD","选项C":"输出通道32","选项B":"输入通道5","选项A":"尺寸5X5","类型":"2-多选"},{"题干":"在关于sigmoid函数，它的性质有：","选项F":"","选项E":"","选项D":"将正权值映射到负数","答案":"ABC","选项C":"将负的权值映射到正值","选项B":"能解决非线性分类问题","选项A":"将输出数据压缩到【0，1】集合范围","类型":"2-多选"},{"题干":"在关于深度神经网络的构成，将卷积层放在前面，将全连接层放在后面，它们的作用是","选项F":"","选项E":"","选项D":"全连接层只能有一层","答案":"ABC","选项C":"激活函数relu可以用到卷积层","选项B":"pooling的下采样能够降低overfitting","选项A":"用卷积层提取特征","类型":"2-多选"},{"题干":"在tensorflow模块中，x = tf.cast(u,tf.float32)的意义，说法正确的是","选项F":"","选项E":"","选项D":"实现类型转化的功能","答案":"BD","选项C":"将u内的数据进行洗牌处理","选项B":"将u内数据转换成float32","选项A":"将随机数赋值给u","类型":"2-多选"},{"题干":"对于w_data = np.mat([[1.0, 3.0]]).T生成的张量维度是","选项F":"","选项E":"","选项D":"是向量【【1，3】】的转置","答案":"ACD","选项C":"是矩阵【【1】，【3】】","选项B":"是向量，值为【1，3】","选项A":"维度是【2，1】的张量","类型":"2-多选"},{"题干":"试问以下哪条tf语句能够描述损失函数","选项F":"","选项E":"","选项D":"loss = tf.reduce_mean(tf.subtract(y，y_data))","答案":"AB","选项C":"loss = tf.reduce_mean(tf.add(y，y_data))","选项B":"loss = tf.reduce_sum(tf.square(y - y_data))","选项A":"loss = tf.reduce_mean(tf.square(y - y_data))","类型":"2-多选"},{"题干":"损失函数，可以由误差向量的总体范数平方定义","选项F":"","选项E":"","选项D":"","答案":"A","选项C":"","选项B":"","选项A":"","类型":"0-判断"},{"题干":"损失函数，是个数量函数，张量维度为0","选项F":"","选项E":"","选项D":"","答案":"A","选项C":"","选项B":"","选项A":"","类型":"0-判断"},{"题干":"对平方范数的损失函数求偏导数的结果，得到一个梯度向量。","选项F":"","选项E":"","选项D":"","答案":"A","选项C":"","选项B":"","选项A":"","类型":"0-判断"},{"题干":"梯度和损失函数一样，也是数量函数","选项F":"","选项E":"","选项D":"","答案":"B","选项C":"","选项B":"","选项A":"","类型":"0-判断"},{"题干":"在寻优的迭代过程中，损失函数的运算结果，从趋势上是逐步降低的。","选项F":"","选项E":"","选项D":"","答案":"A","选项C":"","选项B":"","选项A":"","类型":"0-判断"},{"题干":"全连接层无法实现卷积运算。","选项F":"","选项E":"","选项D":"","答案":"A","选项C":"","选项B":"","选项A":"","类型":"0-判断"},{"题干":"均方损失函数，可以由误差向量的总体范数平方定义","选项F":"","选项E":"","选项D":"","答案":"A","选项C":"","选项B":"","选项A":"","类型":"0-判断"},{"题干":"均方损失函数，是个数量函数，张量维度为0","选项F":"","选项E":"","选项D":"","答案":"A","选项C":"","选项B":"","选项A":"","类型":"0-判断"},{"题干":"对一个平方范数的损失函数求偏导数的结果，得到一个梯度向量。","选项F":"","选项E":"","选项D":"","答案":"A","选项C":"","选项B":"","选项A":"","类型":"0-判断"},{"题干":"任何梯度和损失函数一样，也是数量函数","选项F":"","选项E":"","选项D":"","答案":"B","选项C":"","选项B":"","选项A":"","类型":"0-判断"},{"题干":"在参数训练的迭代过程中，损失函数的运算结果，从趋势上是逐步降低的。","选项F":"","选项E":"","选项D":"","答案":"A","选项C":"","选项B":"","选项A":"","类型":"0-判断"},{"题干":"全连接层无法实现卷积运算，他们互有分工。","选项F":"","选项E":"","选项D":"","答案":"A","选项C":"","选项B":"","选项A":"","类型":"0-判断"}]